{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAfJCaULD2Yp"
   },
   "source": [
    "# Distributed Training of Neural Network Models\n",
    "\n",
    "\n",
    "Below is the basic implementation of Federated Learning code for 2 clients and a server for one communication round using the MNIST dataset.\n",
    "\n",
    "Your task for this lab is to utilize this code as a benchmark and accomplish  the following objectives:\n",
    "\n",
    "1. Comment each section of the code to understand its functionality.\n",
    "\n",
    "2. Experiment with different neural network architectures, varying the number of layers and activation functions\n",
    "\n",
    "3. Assess the model's performance (accuracy, precision, recall, and f-score) as the number of clients changes. Utilize 2, 4, 6, 8, and 10 clients, and plot a graph illustrating the model's performance across varying client counts.\n",
    "\n",
    "4. Introduce one dishonest client for a any sepcific number of clients of your choice. For this client, assign some training labels ('y_train') to a specific label, such as '4'. Analyze how the performance ((accuracy, precision, recall, and f-score)) of the global model is affected by the presence of a dishonest client. Find approximately how many labels need to be maliciously altered so that the performance degrades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rQj0pd83zCS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGQHqF2Y3zF5"
   },
   "outputs": [],
   "source": [
    "np.random.seed(2324422) # Set seed for numpy. Put your SID instead of number '42'\n",
    "random.seed(2324422) # Set seed for Python's built-in random number generator.  Put your SID instead of number '42'\n",
    "tf.random.set_seed(2324422) # Set seed for TensorFlow. Put your SID instead of number '42'\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Mf8sjel39eG"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGo4_zxa39je"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8u-RBPj50Ht",
    "outputId": "829f32a1-1694-43a4-9012-9d19bdf5121a"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FzSanlW4DWD"
   },
   "outputs": [],
   "source": [
    "def create_client_model():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28, 1)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_client_model(model, x_train, y_train, epochs=5):\n",
    "    model.fit(x_train, y_train, epochs=epochs, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faEMcu9L4DeQ"
   },
   "outputs": [],
   "source": [
    "x_train_c1, x_train_c2, y_train_c1, y_train_c2 = train_test_split(x_train, y_train, test_size=0.5, random_state=2324422)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNZLQ0j_5_QN",
    "outputId": "b432caad-65ba-4c03-9234-a8bad83c4a22"
   },
   "outputs": [],
   "source": [
    "print(x_train_c1.shape)\n",
    "print(x_train_c2.shape)\n",
    "print(y_train_c1.shape)\n",
    "print(y_train_c2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NDoAqhf6HIN",
    "outputId": "e506fc63-aa80-4ba1-b2a8-278c1521fd3a"
   },
   "outputs": [],
   "source": [
    "# Create and train client models\n",
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, x_train_c1, y_train_c1)\n",
    "client2_model = train_client_model(client2_model, x_train_c2, y_train_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Knw07uE74Dgp"
   },
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2):\n",
    "    new_weights = []\n",
    "    for w1, w2 in zip(weights1, weights2):\n",
    "        new_weights.append((w1 + w2) / 2)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojdtEncJ4DjB"
   },
   "outputs": [],
   "source": [
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), client2_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnE_5XnS6OUN"
   },
   "outputs": [],
   "source": [
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvhzExvp6Qg8",
    "outputId": "4ea8b282-6176-4db4-f726-cc03e9d871c9"
   },
   "outputs": [],
   "source": [
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFPUa1ZA6W0E"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFq-8E-36W5E",
    "outputId": "573a7dd3-2367-43aa-bb7e-94a09c27a0e4"
   },
   "outputs": [],
   "source": [
    "prediction = global_model.predict(x_test)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = list(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEKOAJ356XLk",
    "outputId": "12337ddf-3d3f-4c31-eac2-bd53e462aaa0"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EsuIANE39qe",
    "outputId": "1f375fc8-2742-4221-9c93-a0bf58e95455"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy test set:\", accuracy_score(y_test, prediction))\n",
    "print(\"precison test set:\", precision_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"Recall test set:\", recall_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"f-score test set:\", f1_score(y_test, prediction, average = 'weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g76dDZ7e5PsN"
   },
   "outputs": [],
   "source": [
    "test_precision= []\n",
    "test_recall = []\n",
    "test_f1_score = []\n",
    "test_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2sH9duA_zWS"
   },
   "outputs": [],
   "source": [
    "test_accuracy.append(0.8508)\n",
    "test_precision.append(0.8820127173009187)\n",
    "test_recall.append(0.8508)\n",
    "test_f1_score.append(0.8522835934707446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_nZSIjnBfE9"
   },
   "source": [
    "4 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ol34p-Sy_zoU"
   },
   "outputs": [],
   "source": [
    "# split data into 4 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEb_yZ1fBizY"
   },
   "outputs": [],
   "source": [
    "client_1 = (x_train[0:15000], y_train[0:15000])\n",
    "client_2 = (x_train[15000:30000], y_train[15000:30000])\n",
    "client_3 = (x_train[30000:45000], y_train[30000:45000])\n",
    "client_4 = (x_train[45000:], y_train[45000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "La4b_ajZBi25",
    "outputId": "92e642ab-78ec-48ce-f8f9-f58492e3cdf6"
   },
   "outputs": [],
   "source": [
    "print(client_1[0].shape)\n",
    "print(client_2[0].shape)\n",
    "print(client_3[0].shape)\n",
    "print(client_4[0].shape)\n",
    "\n",
    "print(client_1[1].shape)\n",
    "print(client_2[1].shape)\n",
    "print(client_3[1].shape)\n",
    "print(client_4[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIRcHQQLBi5D",
    "outputId": "403ce900-bf3e-4a56-8236-6ed731ed19ee"
   },
   "outputs": [],
   "source": [
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "client3_model = create_client_model()\n",
    "client4_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, client_1[0], client_1[1])\n",
    "client2_model = train_client_model(client2_model, client_2[0], client_1[1])\n",
    "client3_model = train_client_model(client3_model, client_3[0], client_1[1])\n",
    "client4_model = train_client_model(client4_model, client_4[0], client_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5XixPAF_zqy"
   },
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2, weights3, weights4):\n",
    "    new_weights = []\n",
    "    for w1, w2, w3, w4 in zip(weights1, weights2,  weights3,  weights4):\n",
    "        new_weights.append((w1 + w2 + w3 + w4) / 4)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRHs1RAGEZtk"
   },
   "outputs": [],
   "source": [
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), client2_model.get_weights(), client3_model.get_weights(), client4_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfN6GVmJEZv7",
    "outputId": "7634fdf7-5b95-42de-9396-137366fb6cb2"
   },
   "outputs": [],
   "source": [
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)\n",
    "\n",
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8fZXim3EZyL",
    "outputId": "329f5eee-a6e1-4cea-e660-6e49982ade94"
   },
   "outputs": [],
   "source": [
    "prediction = global_model.predict(x_test)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = list(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2husRH-OEZ0c",
    "outputId": "7cbbfd7c-2870-4755-893b-a32aa6951c86"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy test set:\", accuracy_score(y_test, prediction))\n",
    "print(\"precison test set:\", precision_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"Recall test set:\", recall_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"f-score test set:\", f1_score(y_test, prediction, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.append(0.3374)\n",
    "test_precision.append(0.35501437213213655)\n",
    "test_recall.append(0.3374)\n",
    "test_f1_score.append(0.2962132458250437)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWQqronzGcEn"
   },
   "source": [
    "6 clients cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUN9YHRYGd4w"
   },
   "outputs": [],
   "source": [
    "client_1 = (x_train[0:10000], y_train[0:10000])\n",
    "client_2 = (x_train[10000:20000], y_train[10000:20000])\n",
    "client_3 = (x_train[20000:30000], y_train[20000:30000])\n",
    "client_4 = (x_train[30000:40000], y_train[30000:40000])\n",
    "client_5 = (x_train[40000:50000], y_train[40000:50000])\n",
    "client_6 = (x_train[50000:], y_train[50000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZulvDQEGXgS",
    "outputId": "051b2727-8625-43a7-e2c4-3d6d48f342b2"
   },
   "outputs": [],
   "source": [
    "print(client_1[0].shape)\n",
    "print(client_2[0].shape)\n",
    "print(client_3[0].shape)\n",
    "print(client_4[0].shape)\n",
    "print(client_5[0].shape)\n",
    "print(client_6[0].shape)\n",
    "\n",
    "print(client_1[1].shape)\n",
    "print(client_2[1].shape)\n",
    "print(client_3[1].shape)\n",
    "print(client_4[1].shape)\n",
    "print(client_5[1].shape)\n",
    "print(client_6[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3odWh-mwGXip",
    "outputId": "67730390-02ec-4bfc-a6cd-b0ae81990240"
   },
   "outputs": [],
   "source": [
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "client3_model = create_client_model()\n",
    "client4_model = create_client_model()\n",
    "client5_model = create_client_model()\n",
    "client6_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, client_1[0], client_1[1])\n",
    "client2_model = train_client_model(client2_model, client_2[0], client_1[1])\n",
    "client3_model = train_client_model(client3_model, client_3[0], client_1[1])\n",
    "client4_model = train_client_model(client4_model, client_4[0], client_1[1])\n",
    "client5_model = train_client_model(client5_model, client_5[0], client_1[1])\n",
    "client6_model = train_client_model(client6_model, client_6[0], client_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5MLqCAHGXlC"
   },
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2, weights3, weights4, weights5, weights6):\n",
    "    new_weights = []\n",
    "    for w1, w2, w3, w4, w5, w6 in zip(weights1, weights2,  weights3,  weights4, weights5, weights6):\n",
    "        new_weights.append((w1 + w2 + w3 + w4 + w5 + w6) / 6)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuinGGgdGXnK"
   },
   "outputs": [],
   "source": [
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), client2_model.get_weights(), client3_model.get_weights(), client4_model.get_weights(),client5_model.get_weights(),client6_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qY02p3OFGXpk",
    "outputId": "fc6752c3-8142-438e-fc7c-00b7134ecba5"
   },
   "outputs": [],
   "source": [
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)\n",
    "\n",
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctaORnw8GXrx",
    "outputId": "73367caf-598d-4f87-901d-c440d992eef8"
   },
   "outputs": [],
   "source": [
    "prediction = global_model.predict(x_test)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = list(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYSLKm-YGXt5",
    "outputId": "7b24fba3-e0d2-42ae-aee0-026604ebf719"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy test set:\", accuracy_score(y_test, prediction))\n",
    "print(\"precison test set:\", precision_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"Recall test set:\", recall_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"f-score test set:\", f1_score(y_test, prediction, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.append(0.2073)\n",
    "test_precision.append(0.2192389494021009)\n",
    "test_recall.append(0.2073)\n",
    "test_f1_score.append(0.15575406556726198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmYXCZHwKifS"
   },
   "source": [
    "8 clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_vWSCvJGXwj"
   },
   "outputs": [],
   "source": [
    "client_1 = (x_train[0:7500], y_train[0:7500])\n",
    "client_2 = (x_train[7500:15000], y_train[7500:15000])\n",
    "client_3 = (x_train[15000:22500], y_train[15000:22500])\n",
    "client_4 = (x_train[22500:30000], y_train[22500:30000])\n",
    "client_5 = (x_train[30000:37500], y_train[30000:37500])\n",
    "client_6 = (x_train[37500:45000], y_train[37500:45000])\n",
    "client_7 = (x_train[45000:52500], y_train[45000:52500])\n",
    "client_8 = (x_train[52500:], y_train[52500:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYS0Vw5vJwW-"
   },
   "outputs": [],
   "source": [
    "print(client_1[0].shape)\n",
    "print(client_2[0].shape)\n",
    "print(client_3[0].shape)\n",
    "print(client_4[0].shape)\n",
    "print(client_5[0].shape)\n",
    "print(client_6[0].shape)\n",
    "print(client_7[0].shape)\n",
    "print(client_8[0].shape)\n",
    "\n",
    "print(client_1[1].shape)\n",
    "print(client_2[1].shape)\n",
    "print(client_3[1].shape)\n",
    "print(client_4[1].shape)\n",
    "print(client_5[1].shape)\n",
    "print(client_6[1].shape)\n",
    "print(client_7[1].shape)\n",
    "print(client_8[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG6Wf5jyJwZV"
   },
   "outputs": [],
   "source": [
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "client3_model = create_client_model()\n",
    "client4_model = create_client_model()\n",
    "client5_model = create_client_model()\n",
    "client6_model = create_client_model()\n",
    "client7_model = create_client_model()\n",
    "client8_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, client_1[0], client_1[1])\n",
    "client2_model = train_client_model(client2_model, client_2[0], client_2[1])\n",
    "client3_model = train_client_model(client3_model, client_3[0], client_3[1])\n",
    "client4_model = train_client_model(client4_model, client_4[0], client_4[1])\n",
    "client5_model = train_client_model(client5_model, client_5[0], client_5[1])\n",
    "client6_model = train_client_model(client6_model, client_6[0], client_6[1])\n",
    "client7_model = train_client_model(client7_model, client_7[0], client_7[1])\n",
    "client8_model = train_client_model(client8_model, client_8[0], client_8[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXh3uhF4Jwbe"
   },
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2, weights3, weights4,  weights5,  weights6,  weights7,  weights8):\n",
    "    new_weights = []\n",
    "    for w1, w2, w3, w4, w5, w6, w7, w8 in zip(weights1, weights2,  weights3,  weights4,  weights5,  weights6,  weights7,  weights8):\n",
    "        new_weights.append((w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8) / 8)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyDp11I_Jwdt"
   },
   "outputs": [],
   "source": [
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), client2_model.get_weights(), \n",
    "                                               client3_model.get_weights(), client4_model.get_weights(),  \n",
    "                                               client5_model.get_weights(), client6_model.get_weights(), \n",
    "                                               client7_model.get_weights(), client8_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-NfW_GUGXyh"
   },
   "outputs": [],
   "source": [
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)\n",
    "\n",
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iryi3SEEKAE2"
   },
   "outputs": [],
   "source": [
    "prediction = global_model.predict(x_test)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = list(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymbl_sU1KAHX"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy test set:\", accuracy_score(y_test, prediction))\n",
    "print(\"precison test set:\", precision_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"Recall test set:\", recall_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"f-score test set:\", f1_score(y_test, prediction, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.append(0.4496)\n",
    "test_precision.append(0.7342762826710872)\n",
    "test_recall.append(0.4496)\n",
    "test_f1_score.append(0.41847081461118935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4ZEjacGKAJl"
   },
   "source": [
    "10 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_1 = (x_train[0:6000],y_train[0:6000])\n",
    "client_2= (x_train[6000:12000],y_train[6000:12000])\n",
    "client_3= (x_train[12000:18000],y_train[12000:18000])\n",
    "client_4= (x_train[18000:24000], y_train[18000:24000])\n",
    "client_5=(x_train[24000:30000], y_train[24000:30000])\n",
    "client_6= (x_train[30000:36000], y_train[30000:36000])\n",
    "client_7=(x_train[36000:42000], y_train[36000:42000])\n",
    "client_8=(x_train[42000:48000], y_train[42000:48000])\n",
    "client_9=(x_train[48000:54000], y_train[48000:54000])\n",
    "client_10=(x_train[54000:],y_train[54000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client_1[0].shape)\n",
    "print(client_2[0].shape)\n",
    "print(client_3[0].shape)\n",
    "print(client_4[0].shape)\n",
    "print(client_5[0].shape)\n",
    "print(client_6[0].shape)\n",
    "print(client_7[0].shape)\n",
    "print(client_8[0].shape)\n",
    "print(client_9[0].shape)\n",
    "print(client_10[0].shape)\n",
    "\n",
    "print(client_1[1].shape)\n",
    "print(client_2[1].shape)\n",
    "print(client_3[1].shape)\n",
    "print(client_4[1].shape)\n",
    "print(client_5[1].shape)\n",
    "print(client_6[1].shape)\n",
    "print(client_7[1].shape)\n",
    "print(client_8[1].shape)\n",
    "print(client_9[1].shape)\n",
    "print(client_10[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "client3_model = create_client_model()\n",
    "client4_model = create_client_model()\n",
    "client5_model = create_client_model()\n",
    "client6_model = create_client_model()\n",
    "client7_model = create_client_model()\n",
    "client8_model = create_client_model()\n",
    "client9_model = create_client_model()\n",
    "client10_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, client_1[0], client_1[1])\n",
    "client2_model = train_client_model(client2_model, client_2[0], client_2[1])\n",
    "client3_model = train_client_model(client3_model, client_3[0], client_3[1])\n",
    "client4_model = train_client_model(client4_model, client_4[0], client_4[1])\n",
    "client5_model = train_client_model(client5_model, client_5[0], client_5[1])\n",
    "client6_model = train_client_model(client6_model, client_6[0], client_6[1])\n",
    "client7_model = train_client_model(client7_model, client_7[0], client_7[1])\n",
    "client8_model = train_client_model(client8_model, client_8[0], client_8[1])\n",
    "client9_model = train_client_model(client8_model, client_9[0], client_9[1])\n",
    "client10_model = train_client_model(client8_model, client_10[0], client_10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2, weights3, weights4,  weights5,  weights6,  weights7,  weights8, weights9, weights10):\n",
    "    new_weights = []\n",
    "    for w1, w2, w3, w4, w5, w6, w7, w8, w9, w10 in zip(weights1, weights2,  weights3,  weights4,  weights5,  weights6,  weights7,  weights8, weights9, weights10):\n",
    "        new_weights.append((w1 + w2 + w3 + w4 + w5 + w6 + w7 + w8 + w9 + w10) / 10)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), client2_model.get_weights(), \n",
    "                                               client3_model.get_weights(), client4_model.get_weights(),  \n",
    "                                               client5_model.get_weights(), client6_model.get_weights(), \n",
    "                                               client7_model.get_weights(), client8_model.get_weights(),\n",
    "                                               client9_model.get_weights(), client10_model.get_weights())\n",
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "prediction = global_model.predict(x_test)\n",
    "print(prediction.shape)\n",
    "\n",
    "prediction = list(prediction.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy test set:\", accuracy_score(y_test, prediction))\n",
    "print(\"precison test set:\", precision_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"Recall test set:\", recall_score(y_test, prediction, average = 'weighted'))\n",
    "print(\"f-score test set:\", f1_score(y_test, prediction, average = 'weighted'))\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy.append(0.6243)\n",
    "test_precision.append(0.8546927376488528)\n",
    "test_recall.append(0.6243)\n",
    "test_f1_score.append(0.6157209884017654)\n",
    "\n",
    "print(test_accuracy)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "print(test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model's performance for the number of clients ranging from 2, 4, 6, 8, and 10.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorMetrics = []\n",
    "ErrorMetrics.append(test_accuracy)\n",
    "ErrorMetrics.append(test_precision)\n",
    "ErrorMetrics.append(test_recall)\n",
    "ErrorMetrics.append(test_f1_score)\n",
    "\n",
    "print(ErrorMetrics)\n",
    "\n",
    "ErrorMetrics_pd = pd.DataFrame(ErrorMetrics)\n",
    "ErrorMetrics_pd.columns = [2,4,6,8,10]\n",
    "ErrorMetrics_pd = ErrorMetrics_pd.T\n",
    "ErrorMetrics_pd.columns = ['Accuracy','Precision','Recall','F1_Score']\n",
    "ErrorMetrics_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorMetrics_pd.plot.bar(width=0.7, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dishonest \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 4 clients\n",
    "client_1 = (x_train[0:15000], y_train[0:15000])\n",
    "client_2 = (x_train[15000:30000], y_train[15000:30000])\n",
    "client_3 = (x_train[30000:45000], y_train[30000:45000])\n",
    "client_4 = (x_train[45000:], y_train[45000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_3[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_3[1][:3000] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client_1[0].shape)\n",
    "print(client_2[0].shape)\n",
    "print(client_3[0].shape)\n",
    "print(client_4[0].shape)\n",
    "\n",
    "print(client_1[1].shape)\n",
    "print(client_2[1].shape)\n",
    "print(client_3[1].shape)\n",
    "print(client_4[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train client models\n",
    "client1_model = create_client_model()\n",
    "client2_model = create_client_model()\n",
    "client3_model = create_client_model()\n",
    "client4_model = create_client_model()\n",
    "\n",
    "client1_model = train_client_model(client1_model, client_1[0], client_1[1])\n",
    "client2_model = train_client_model(client2_model, client_2[0], client_1[1])\n",
    "client3_model = train_client_model(client3_model, client_3[0], client_1[1])\n",
    "client4_model = train_client_model(client4_model, client_4[0], client_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated averaging\n",
    "def federated_average_weights(weights1, weights2, weights3, weights4):\n",
    "    new_weights = []\n",
    "    for w1, w2, w3, w4 in zip(weights1, weights2, weights3, weights4):\n",
    "        new_weights.append((w1 + w2 + w3 + w4 ) / 4)\n",
    "    return new_weights\n",
    "\n",
    "\n",
    "# Aggregate models\n",
    "aggregated_weights = federated_average_weights(client1_model.get_weights(), \n",
    "                                               client2_model.get_weights(), \n",
    "                                               client3_model.get_weights(),\n",
    "                                               client4_model.get_weights())\n",
    "                                             \n",
    "# Create global model and set weights\n",
    "global_model = create_client_model()\n",
    "global_model.set_weights(aggregated_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate global model\n",
    "test_loss, test_acc = global_model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "predictions = global_model.predict(x_test)\n",
    "print(predictions.shape)\n",
    "\n",
    "predictions = list(predictions.argmax(axis=1))\n",
    "\n",
    "print(\"Accuracy test set: \", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"Precision test set: \", precision_score(y_test, predictions, average = 'weighted' )) \n",
    "print(\"Recall test set: \", recall_score(y_test, predictions, average = 'weighted' ))\n",
    "print(\"F-score test set: \", f1_score(y_test, predictions, average = 'weighted' ))\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_dishonest  = []\n",
    "test_precision_dishonest = []\n",
    "test_recall_dishonest    = []\n",
    "test_f1_score_dishonest  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_dishonest.append(test_accuracy[2])\n",
    "test_precision_dishonest.append(test_precision[2])\n",
    "test_recall_dishonest.append(test_recall[2])\n",
    "test_f1_score_dishonest.append(test_f1_score[2])\n",
    "\n",
    "test_accuracy_dishonest.append(0.3603)\n",
    "test_precision_dishonest.append(0.423169487718241)\n",
    "test_recall_dishonest.append(0.3603)\n",
    "test_f1_score_dishonest.append(0.3296364992938911)\n",
    "\n",
    "print(test_accuracy_dishonest)\n",
    "print(test_precision_dishonest)\n",
    "print(test_recall_dishonest)\n",
    "print(test_f1_score_dishonest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the model's performance for the 4 clients, one of them (number=3) is dishonest\n",
    "\n",
    "ErrorMetrics = []\n",
    "ErrorMetrics.append(test_accuracy_dishonest)\n",
    "ErrorMetrics.append(test_precision_dishonest)\n",
    "ErrorMetrics.append(test_recall_dishonest)\n",
    "ErrorMetrics.append(test_f1_score_dishonest)\n",
    "\n",
    "print(ErrorMetrics)\n",
    "\n",
    "ErrorMetrics_pd = pd.DataFrame(ErrorMetrics)\n",
    "ErrorMetrics_pd.columns = ['All are honest', '#3 is dishonest']\n",
    "ErrorMetrics_pd = ErrorMetrics_pd.T\n",
    "ErrorMetrics_pd.columns = ['Accuracy','Precision','Recall','F1_Score']\n",
    "ErrorMetrics_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorMetrics_pd.plot.bar(width=0.7, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeKbFr6UHMPx"
   },
   "source": [
    "# Lab Logbook requirement: Document the following in lablogbook\n",
    "\n",
    "1. Plot the model's performance for the number of clients ranging from 2, 4, 6, 8, and 10.\n",
    "\n",
    "2. For any specified number of clients, compare the model's performance when one (or more) dishonest clients are present. Plot the performance metrics before and after the presence of dishonest clients.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQVf56VHHNQe"
   },
   "source": [
    "# Challenges (Optional):\n",
    "\n",
    "## The above code is for one communication round. Write code for multiple communication rounds. In each communication round, clients will train the model on a new dataset. Then the server will merge all these models. Subsequently, the clients will retrain the merged model in the next communication round.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
